{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paddlepaddle paddleocr deep_tranlator PIL langdetect pytesseract\n",
    "from paddleocr import PaddleOCR\n",
    "from deep_translator import GoogleTranslator\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image):\n",
    "    img_array = np.array(image)\n",
    "    print(\"Image Array Shape:\", img_array.shape)\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "    results = ocr.ocr(img_array, cls=True)\n",
    "    if results[0] is None:\n",
    "        return []\n",
    "    texts_with_positions = [line[1][0] for result in results for line in result]\n",
    "    return texts_with_positions\n",
    "\n",
    "def translate_text(text, dest_language='en'):\n",
    "    return GoogleTranslator(source='auto', target=dest_language).translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Array Shape: (225, 225, 3)\n",
      "[2024/09/04 16:28:51] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/user/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/user/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/user/Meet_Patel/new1/newVenv/lib/python3.12/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/user/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/09/04 16:28:52] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.029481887817382812\n",
      "[2024/09/04 16:28:52] ppocr DEBUG: cls num  : 2, elapsed : 0.007188320159912109\n",
      "[2024/09/04 16:28:52] ppocr DEBUG: rec_res num  : 2, elapsed : 0.11164569854736328\n"
     ]
    }
   ],
   "source": [
    "file = \"/home/user/Meet_Patel/new1/OCR_documents/guj.png\"\n",
    "image = Image.open(file).convert('RGB')\n",
    "ocr_text = extract_text(image)\n",
    "translated_text = [translate_text(text) for text in ocr_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: ચોર, વ્યસની, પાખંડી, કામી તથા કિમીચાગર\n",
      "માનવોન સંગ કરવો નહી.\n",
      "\f\n",
      "Translated Text: Thieves, addicts, traitors, crooks and cheaters\n",
      "Do not associate with humans.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Set the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use Tesseract to extract text\n",
    "    # Using Hindi ('hin') as a proxy language for OCR\n",
    "    extracted_text = pytesseract.image_to_string(gray, lang='guj')\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "def translate_text(text, dest_language='en'):\n",
    "    translator = GoogleTranslator(source='auto', target=dest_language)\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "def main(image_path):\n",
    "    # Extract text from image\n",
    "    extracted_text = extract_text_from_image(image_path)\n",
    "    print(\"Extracted Text:\", extracted_text)\n",
    "    \n",
    "    # Translate the extracted text into English\n",
    "    translated_text = translate_text(extracted_text, 'en')\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace this path with the actual path to your image\n",
    "    image_path = \"/home/user/Meet_Patel/new1/OCR_documents/guj.png\"\n",
    "    main(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text (Hindi): । लोदीकाल में किले में महल, कुँऐ और (\n",
      "केले और उसके विशाल खजाने पर अई\n",
      "दिया गया। बाबर किले में इव्ाहिम के\n",
      "_का यहीं राज्याभिषेक हुआ। १६३६ में\n",
      "बचाया था, उस उपकार के बदले हुमाः\n",
      "'ढिलग्राम में हुमायूँ हार गया। पौँच बर्ष\n",
      "\f\n",
      "Translated Text: During the Lodhi period, the fort was given palaces, wells and a huge treasure. Babur was crowned here. In 1636, he was saved. In return for that favour, Humayun was defeated at Dhilgram. After five years, Humayun was defeated.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Set the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# List of supported languages and their respective Tesseract language codes\n",
    "supported_languages = {\n",
    "    'Hindi': 'hin',\n",
    "    'Gujarati': 'guj',\n",
    "    'Marathi': 'mar',\n",
    "    # Add more languages as needed\n",
    "}\n",
    "\n",
    "def extract_text_from_image(image_path, lang_code):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use Tesseract to extract text\n",
    "    extracted_text = pytesseract.image_to_string(gray, lang=lang_code)\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "def translate_text(text, dest_language='en'):\n",
    "    translator = GoogleTranslator(source='auto', target=dest_language)\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "def main(image_path, language):\n",
    "    # Check if the language is supported\n",
    "    if language not in supported_languages:\n",
    "        print(f\"Language '{language}' is not supported.\")\n",
    "        return\n",
    "    \n",
    "    # Get the Tesseract language code\n",
    "    lang_code = supported_languages[language]\n",
    "    \n",
    "    # Extract text from image\n",
    "    extracted_text = extract_text_from_image(image_path, lang_code)\n",
    "    print(f\"Extracted Text ({language}):\", extracted_text)\n",
    "    \n",
    "    # Translate the extracted text into English\n",
    "    translated_text = translate_text(extracted_text, 'en')\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these paths and language with actual values\n",
    "    # image_path = \"path_to_your_image.jpg\"\n",
    "    # language = \"Gujarati\"  # or \"Hindi\", \"Marathi\", etc.\n",
    "    \n",
    "    # image_path = \"guj.png\"\n",
    "    image_path = \"hindi.png\"\n",
    "    language = \"Hindi\"\n",
    "    \n",
    "    main(image_path, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language: hin\n",
      "Extracted Text: । लोदीकाल में किले में महल, कुँऐ और\n",
      "केले और उसके विशाल खजाने पर\n",
      "दिया गया। बाबर किले नें इव्ाहिस के\n",
      "का यहीं राज्णमिषेक हुआ। १३३६ में\n",
      "बचाया था, उस उपकार के बदले हुमाः\n",
      "'डिलग्रास में हुमायूँ हार गया । पाँच बर्ष\n",
      "Translated Text: In the Lodhi period, the fort had palaces, wells and forts and its vast treasure was given to Babur. Babur was crowned king here. In return for the favour of saving the fort in 1336, Humayun was defeated in the battle of Dilgras. After five years, he was made the king of the fort.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "\n",
    "# Set the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# Mapping of detected languages to Tesseract language codes\n",
    "lang_map = {\n",
    "    'hi': 'hin',\n",
    "    'gu': 'guj',\n",
    "    'mr': 'mar',\n",
    "    'bn': 'ben',\n",
    "    'ta': 'tam',\n",
    "    'te': 'tel',\n",
    "    'kn': 'kan',\n",
    "    'ml': 'mal',\n",
    "    'pa': 'pan',\n",
    "    'or': 'ori',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "def extract_text_from_image(image_path, lang_code='eng'):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to preprocess the image\n",
    "    threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Perform text extraction\n",
    "    config = f'--oem 3 --psm 6 -l {lang_code}'\n",
    "    text = pytesseract.image_to_string(threshold, config=config)\n",
    "    return text.strip()\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang_map.get(lang, 'eng')\n",
    "    except:\n",
    "        return 'eng'\n",
    "\n",
    "def translate_text(text, dest_language='en'):\n",
    "    translator = GoogleTranslator(source='auto', target=dest_language)\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "def main(image_path):\n",
    "    # First, try to extract text using a general approach\n",
    "    initial_text = extract_text_from_image(image_path, 'eng+hin+guj+mar')\n",
    "    \n",
    "    # Detect the language of the extracted text\n",
    "    detected_lang_code = detect_language(initial_text)\n",
    "    \n",
    "    # Re-extract text using the detected language for better accuracy\n",
    "    if detected_lang_code != 'eng':\n",
    "        extracted_text = extract_text_from_image(image_path, detected_lang_code)\n",
    "    else:\n",
    "        extracted_text = initial_text\n",
    "    \n",
    "    print(f\"Detected Language: {detected_lang_code}\")\n",
    "    print(f\"Extracted Text: {extracted_text}\")\n",
    "    \n",
    "    # Translate the extracted text into English\n",
    "    translated_text = translate_text(extracted_text, 'en')\n",
    "    print(\"Translated Text:\", translated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"hindi.png\"\n",
    "    main(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
